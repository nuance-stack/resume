{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "h1wXvjnNrfif"
   },
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "#Importing necessary libraries \n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DwSVIBfD0qNR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import the dataset and define the feature as well as the target datasets / columns \n",
    "data = pd.read_csv(\"zoo.csv\")\n",
    "feature_names=['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone', \n",
    "               'breathes','venomous','fins','legs','tail','domestic','catsize']\n",
    "features = data[feature_names]\n",
    "target = data['class_type']\n",
    "#We drop the animal names since this is not a good feature to split the data on  \n",
    "data=data.drop(['animal_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JVym-1Gp07wb"
   },
   "outputs": [],
   "source": [
    "#Write a function to find the entropy on a split \"target_col\"\n",
    "def entropy(df,target_col):\n",
    "\n",
    "    #Count how much of each different value \n",
    "    count=df[target_col].value_counts()\n",
    "    \n",
    "    #Find probability of different values\n",
    "    probabilities=count/len(df)\n",
    "    \n",
    "    entropy=0\n",
    "    \n",
    "    #Find entropy using formula\n",
    "    for i in probabilities:\n",
    "        entropy += -i*np.log2(i)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qGD6L7r5gGrL"
   },
   "outputs": [],
   "source": [
    "#Find the entropy of all the features in the dataset\n",
    "entropies = {}\n",
    "for j in features.columns:\n",
    "       entropies[j] = entropy(data,j)\n",
    "\n",
    "#Save all the feature names in an array \"feature names\"\n",
    "#feature_names=['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone', 'breathes','venomous','fins','legs','tail','domestic','catsize']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xwVaEI7X1VFc"
   },
   "outputs": [],
   "source": [
    "#Write a function to calculate Information Gain on a split attribute and a target column\n",
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):       \n",
    "    \n",
    "    #Calculate the entropy of the total dataset  \n",
    "    target_entropy=entropy(data,target_name)\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute   \n",
    "    sub={}\n",
    "    for value in data[split_attribute_name].unique():\n",
    "        sub[value]=data.loc[data[split_attribute_name]==value]\n",
    "    \n",
    "    #Calculate the weighted entropy  \n",
    "    entropy_avg=0\n",
    "    for value,subset in sub.items():\n",
    "        p=len(subset)/len(data)\n",
    "        entropy_avg+=p*entropy(subset,target_name)\n",
    "    \n",
    "    #Calculate the information gain  \n",
    "    information_gain=target_entropy-entropy_avg\n",
    "    return information_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YFEBzgI41eeJ"
   },
   "outputs": [],
   "source": [
    "#Import Decision Tree Classifier from sklearn \n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Split the given data into 80 percent training data and 20 percent testing data\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features,target, test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AZXmFwU410JI"
   },
   "outputs": [],
   "source": [
    "#Fit the given data\n",
    "model_tree = DecisionTreeClassifier(criterion = 'entropy')\n",
    "model_tree = model_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aTreS7NKkFqH"
   },
   "outputs": [],
   "source": [
    "#Make a prediction on the test data and return the percentage of accuracy\n",
    "ypred_entropy = model_tree.predict(x_test)\n",
    "acc=metrics.accuracy_score(y_test, ypred_entropy)\n",
    "ans[2]=acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MAHqi9VFOCJQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juniu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\juniu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\juniu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 10},\n",
       " '2': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3},\n",
       " '3': {'precision': 1.0,\n",
       "  'recall': 0.6666666666666666,\n",
       "  'f1-score': 0.8,\n",
       "  'support': 3},\n",
       " '4': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0},\n",
       " '6': {'precision': 0.6666666666666666,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.8,\n",
       "  'support': 2},\n",
       " '7': {'precision': 1.0,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.6666666666666666,\n",
       "  'support': 2},\n",
       " 'accuracy': 0.9047619047619048,\n",
       " 'macro avg': {'precision': 0.8095238095238095,\n",
       "  'recall': 0.738095238095238,\n",
       "  'f1-score': 0.7523809523809524,\n",
       "  'support': 21},\n",
       " 'weighted avg': {'precision': 0.9682539682539681,\n",
       "  'recall': 0.9047619047619048,\n",
       "  'f1-score': 0.9206349206349206,\n",
       "  'support': 21}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use sklearn to make a classification report and a confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm=metrics.confusion_matrix(y_test, ypred_entropy)\n",
    "cr=metrics.classification_report(y_test, ypred_entropy,output_dict=True)\n",
    "cr"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment Decision Tress.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
